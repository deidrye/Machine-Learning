{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uut6xA2Y7sUD"
      },
      "source": [
        "# Логистическая регрессия для задач анализа текстов\n",
        "Для набора твитов вам будет необходимо определить обучить модель логистической регрессии для определения тональности твитов."
      ],
      "id": "uut6xA2Y7sUD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuD-6abp7sUH"
      },
      "source": [
        "## Import functions and data"
      ],
      "id": "GuD-6abp7sUH"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/nxdok8u3d24re5n/utils.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_A_XUNDK5L-",
        "outputId": "43e124fa-4e4c-4199-f68c-62679051a610"
      },
      "id": "R_A_XUNDK5L-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-27 17:47:30--  https://www.dropbox.com/s/nxdok8u3d24re5n/utils.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/nxdok8u3d24re5n/utils.py [following]\n",
            "--2021-12-27 17:47:31--  https://www.dropbox.com/s/raw/nxdok8u3d24re5n/utils.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com/cd/0/inline/Bcr2AOk_OKVR7fjuAhxFoDh7cG0R1NFDhiBg4R-MeVBhfbbBjXPiRd14Jm-K-WMinuJFFxDcHXk3axJWXMgYmaCZldpyB2StzaeVDJKvjM9O_ANzrvKMb5DXDSYvfOnrh27lMrLzPgD8gmCx4Vsis8we/file# [following]\n",
            "--2021-12-27 17:47:31--  https://uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com/cd/0/inline/Bcr2AOk_OKVR7fjuAhxFoDh7cG0R1NFDhiBg4R-MeVBhfbbBjXPiRd14Jm-K-WMinuJFFxDcHXk3axJWXMgYmaCZldpyB2StzaeVDJKvjM9O_ANzrvKMb5DXDSYvfOnrh27lMrLzPgD8gmCx4Vsis8we/file\n",
            "Resolving uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com (uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com (uca8cbda63621bdcfdf048278c16.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2265 (2.2K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   2.21K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-27 17:47:32 (286 MB/s) - ‘utils.py’ saved [2265/2265]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/0cunnvacrz5kur3/w1_unittest.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh2mObHnK67w",
        "outputId": "3de29638-4348-4d6c-cdb8-c1153b6947d2"
      },
      "id": "oh2mObHnK67w",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-27 17:47:32--  https://www.dropbox.com/s/0cunnvacrz5kur3/w1_unittest.py\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/0cunnvacrz5kur3/w1_unittest.py [following]\n",
            "--2021-12-27 17:47:32--  https://www.dropbox.com/s/raw/0cunnvacrz5kur3/w1_unittest.py\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com/cd/0/inline/BcrqOT2s1T2kcvKB4LnXEPqEvmONK4P9RQ4gFcSsIA6CPFBCBusV86C-fyrDZcXiMU4UngfSLnanwMz4K-YHByV_1SR-5EfZQadff2DSt3J6NgIlpyITcxCa1B6kwsqw8Hf2d3-gNUoMmpIDZSSIvgMV/file# [following]\n",
            "--2021-12-27 17:47:32--  https://ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com/cd/0/inline/BcrqOT2s1T2kcvKB4LnXEPqEvmONK4P9RQ4gFcSsIA6CPFBCBusV86C-fyrDZcXiMU4UngfSLnanwMz4K-YHByV_1SR-5EfZQadff2DSt3J6NgIlpyITcxCa1B6kwsqw8Hf2d3-gNUoMmpIDZSSIvgMV/file\n",
            "Resolving ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com (ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com (ucefd68990cceec17c49d2822dd9.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19631 (19K) [text/plain]\n",
            "Saving to: ‘w1_unittest.py’\n",
            "\n",
            "w1_unittest.py      100%[===================>]  19.17K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-12-27 17:47:33 (3.44 MB/s) - ‘w1_unittest.py’ saved [19631/19631]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elS9aOiT7sUI",
        "outputId": "f4aa3a92-3def-41eb-cb01-2e32e996093b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "from os import getcwd\n",
        "# Модуль для тестирования\n",
        "import w1_unittest\n",
        "\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "id": "elS9aOiT7sUI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xftdBtk7sUK"
      },
      "source": [
        "### Imported functions\n",
        "\n",
        "[Документация для датасета](http://www.nltk.org/howto/twitter.html).\n",
        "\n",
        "#### В модуле utils.py реализованы некоторые полезные функции для предобработки данных и выполнения задания:\n",
        "* process_tweet: производит предобработку твитов: удаляются стоп-слова, производится токенизация и стемминг.\n",
        "* build_freqs: производится рассчет количества присутствия определенного слова в корпусе для твитов, принадлежащих классу '1' или '0', затем строится словарь частот 'freqs', где ключом является пара (word,label), а значением - соответствующая частота."
      ],
      "id": "5xftdBtk7sUK"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zDDF9Iqs7sUK"
      },
      "outputs": [],
      "source": [
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ],
      "id": "zDDF9Iqs7sUK"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bTTQOEi67sUL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples \n",
        "\n",
        "from utils import process_tweet, build_freqs"
      ],
      "id": "bTTQOEi67sUL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM97SNay7sUL"
      },
      "source": [
        "### Подготовка данных\n",
        "* `twitter_samples` датасет, содержащий 5000 поизитивных и 5000 негативных твитов.  "
      ],
      "id": "AM97SNay7sUL"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XT5LZYqq7sUM"
      },
      "outputs": [],
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "id": "XT5LZYqq7sUM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrM--rzT7sUN"
      },
      "source": [
        "* Train test split: 20% для тестового набора и 80% - для обучения.\n"
      ],
      "id": "hrM--rzT7sUN"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xU5WXvIz7sUO"
      },
      "outputs": [],
      "source": [
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg"
      ],
      "id": "xU5WXvIz7sUO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUcwz_ZH7sUO"
      },
      "source": [
        "* Создаем numpy-массив для позитивныз и негативных меток классов."
      ],
      "id": "WUcwz_ZH7sUO"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fYTo2xjA7sUO"
      },
      "outputs": [],
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "id": "fYTo2xjA7sUO"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMs2r2C_7sUP",
        "outputId": "52f98da1-811e-47ab-be93-89ed02699aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_y.shape = (8000, 1)\n",
            "test_y.shape = (2000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"train_y.shape = \" + str(train_y.shape))\n",
        "print(\"test_y.shape = \" + str(test_y.shape))"
      ],
      "id": "mMs2r2C_7sUP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eL5POew7sUP"
      },
      "source": [
        "* Посмотрите в модуле utils.py как работает функция создания частотного словаря\n",
        "\n",
        "```Python\n",
        "    for y,tweet in zip(ys, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "```"
      ],
      "id": "0eL5POew7sUP"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-fEvzIj7sUQ",
        "outputId": "a4c3e8ee-a685-4dbf-8bd4-6264edb7c0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(freqs) = <class 'dict'>\n",
            "len(freqs) = 11436\n"
          ]
        }
      ],
      "source": [
        "# строим частотный словарь\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "# check the output\n",
        "print(\"type(freqs) = \" + str(type(freqs)))\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "id": "K-fEvzIj7sUQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th9hhPrF7sUQ"
      },
      "source": [
        "#### Ожидаемый вывод\n",
        "```\n",
        "type(freqs) = <class 'dict'>\n",
        "len(freqs) = 11436\n",
        "```"
      ],
      "id": "Th9hhPrF7sUQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6fO2NLg7sUQ"
      },
      "source": [
        "### Обработка твитов\n",
        "С помощью функции 'process_tweet' разделите твиты на список слов, удалите стоп-слова и проведите стемминг."
      ],
      "id": "m6fO2NLg7sUQ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlwGO2E67sUQ",
        "outputId": "cfd14b00-3d51-42ef-ad6c-50cbcbe65232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example of a positive tweet: \n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ]
        }
      ],
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[0])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[0]))"
      ],
      "id": "TlwGO2E67sUQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyPDkAvU7sUR"
      },
      "source": [
        "#### Ожидаемый вывод\n",
        "```\n",
        "This is an example of a positive tweet: \n",
        " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
        " \n",
        "This is an example of the processes version: \n",
        " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n",
        "```"
      ],
      "id": "eyPDkAvU7sUR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usAKipsJ7sUR"
      },
      "source": [
        "# Часть 1: Логистическая регрессия\n",
        "\n",
        "\n",
        "### Часть 1.1: Сигмойда\n",
        " \n",
        "* Функция сигмойды определяется следующим образом: \n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
        "\n",
        "Она отображает входное значение 'z' в число, лежащее на отрезке от 0 до 1, и может рассматриваться как вероятность. "
      ],
      "id": "usAKipsJ7sUR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGQTkJpq7sUR"
      },
      "source": [
        "#### Оеализуйте вычисление сигмойды\n",
        "* Функция должна работать как со скалярным z так и с вектором"
      ],
      "id": "iGQTkJpq7sUR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4SiJ9B7sUS"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Подсказки</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html\" > numpy.exp </a> </li>\n",
        "\n",
        "</ul>\n",
        "</p>\n",
        "\n"
      ],
      "id": "gV4SiJ9B7sUS"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SzF7YxZE7sUS"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z): \n",
        "    '''\n",
        "    Input:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    # Вычисление сигмойды z\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return h"
      ],
      "id": "SzF7YxZE7sUS"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MSBgVqBU7sUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ff9851-49bd-4aa5-ae28-5d189310c0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS!\n",
            "CORRECT!\n"
          ]
        }
      ],
      "source": [
        "# Testing your function \n",
        "if (sigmoid(0) == 0.5):\n",
        "    print('SUCCESS!')\n",
        "else:\n",
        "    print('Oops!')\n",
        "\n",
        "if (sigmoid(4.92) == 0.9927537604041685):\n",
        "    print('CORRECT!')\n",
        "else:\n",
        "    print('Oops again!')"
      ],
      "id": "MSBgVqBU7sUS"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SkOFQdAO7sUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4197f197-937b-4e1a-f55e-092250e0abcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Test your function\n",
        "w1_unittest.test_sigmoid(sigmoid)"
      ],
      "id": "SkOFQdAO7sUS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOtoKh017sUT"
      },
      "source": [
        "### Логистическая регрессия: Регрессия и сигмойда\n",
        "\n",
        "Логистическая регрессия - это, по сути, применение сигмойды к выводу линейной регрессии.\n",
        "\n",
        "Регрессия:\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "$\\theta$ - эта веса модели \"weights\". \n",
        "\n",
        "Логистическая регрессия\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "'z' называются логитами ('logits')."
      ],
      "id": "IOtoKh017sUT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIgFP9mh7sUT"
      },
      "source": [
        "### Часть 1.2 Функция потерь и градиент\n",
        "\n",
        "Функция потерь, используемая при обучении логистической регрессии - это log loss, усредненный по всем обучающим примерам:\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
        "* $m$ - количество обучающих примеров\n",
        "* $y^{(i)}$ - истинный класс 'i'-го объекта обучающей выборки.\n",
        "* $h(z^{(i)})$ - предсказание модели для 'i'-го объекта обучающей выборки.\n",
        "\n",
        "Значение функции потерь для одного объекта определяется следующим образом:\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* Все значения $h$ лежат на отрезке от 0 до 1, так что logs принимают отрицательное значение. Поэтому функция потерь умножается на -1.\n",
        "* Заметьте, что если модель дает предсказание 1 ($h(z(\\theta)) = 1$) и истинный класс $y_{true}$ также равен 1, то loss на обучении равен 0. \n",
        "* Аналогично, если модель предсказывает 0 ($h(z(\\theta)) = 0$) и $y_{true}=0$, то loss = 0. \n",
        "* Однако, если предсказание модели близко к 1 ($h(z(\\theta)) = 0.9999$), а $y_{true}=0$, то второе слагаемое в формуле loss станет большим отрицательным числом, после умножения на -1, значение станет большим положительным числом. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$. При этом, чем ближе значение модели будет к 1, тем больше будет становится loss."
      ],
      "id": "SIgFP9mh7sUT"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikf11jA97sUT",
        "outputId": "6b540bcf-2191-4870-cc15-d15bee93a6a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976294"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
      ],
      "id": "ikf11jA97sUT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNd1v2U87sUT"
      },
      "source": [
        "* Аналогично, если предсказание модели близко к 0 ($h(z) = 0.0001$), но $y_{true} = 1$, то первое слагаемое в формуле будет большим числом: $-1 \\times log(0.0001) \\approx 9.2$. Чем ближе предсказание к 0, тем больше становится loss."
      ],
      "id": "rNd1v2U87sUT"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3NOx8vh7sUT",
        "outputId": "2a59e68e-ae52-4780-d759-f08c4199dda8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976182"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "-1 * np.log(0.0001) # loss is about 9.2"
      ],
      "id": "-3NOx8vh7sUT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uenru1Ch7sUT"
      },
      "source": [
        "#### Обновление весов\n",
        "\n",
        "Для обновления весов $\\theta$, необходимо реализовать градиентный спуск для улучшения качества прогнозов модели и уменьшения loss.  \n",
        "Градиент функции потерь $J$, вычисленный относительного одного из весов $\\theta_j$:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j \\tag{5}$$\n",
        "* 'i' индекс по всем 'm' обучающим примерам.\n",
        "* 'j' индекс веса $\\theta_j$, так что $x^{(i)}_j$ - это признак, при котором стоит вес $\\theta_j$\n",
        "\n",
        "* Для обновления веса $\\theta_j$, мы вычитаем из коэффициента, полученного на предыдущем шаге градиент с коэффициентом $\\alpha$:\n",
        "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
        "* Коэффициент $\\alpha$ - это шаг, который контролирует, насколько сильно мы будем двигаться в сторону антиградиента.\n"
      ],
      "id": "Uenru1Ch7sUT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m46AtFiU7sUU"
      },
      "source": [
        "## Задание: Реаизуйте функцию градиентного спуска\n",
        "* Количество итераций 'num_iters\" - это количсетво проходов по всему обучающему набору.\n",
        "* На каждой итерации, вам необходимо вычислить функцию потерь для всех обучающих примеров ('m'), и по всем признакам.\n",
        "* Вместо обновления одного веса $\\theta_i$ за раз, будем обновлять весь вектор сразу:  \n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\ \n",
        "\\theta_2 \n",
        "\\\\ \n",
        "\\vdots\n",
        "\\\\ \n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "* Размерность $\\mathbf{\\theta}$ - (n+1, 1), где 'n' - число признаков, $\\theta_0$ - это вес, который стоит при фиктивном константном признаке 1 (bias) ($\\mathbf{x_0}$ = 1).\n",
        "* 'logits', 'z', вычисляются умножением матрицы объекты-признаки 'x' на вектор весов 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
        "    * $\\mathbf{x}$ имеет размерность (m, n+1) \n",
        "    * $\\mathbf{\\theta}$: имеет размерность (n+1, 1)\n",
        "    * $\\mathbf{z}$: имеет размерность (m, 1)\n",
        "* Предсказание 'h' вычисляется применением сигмойды 'z': $h(z) = sigmoid(z)$ и имеет размерность (m,1).\n",
        "* Функция потерь $J$ вычисляется как скалярное произведение 'y' и 'log(h)'.  Так как оба 'y' и 'h' имеют размерность (m,1), необходимо транспонировать вектор слева, так что умножение строки на колонку будет представлять скалярное произведение.\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
        "* Обновление весов также будет происходит в векторной форме.  Поскольку размерность $\\mathbf{x}$ - (m, n+1), а размерность $\\mathbf{h}$ и $\\mathbf{y}$ - (m, 1), нужно транспонировать $\\mathbf{x}$ и поставить его слева при умножении матриц, тогда мы получим нужный ответ размерности (n+1, 1):\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
      ],
      "id": "m46AtFiU7sUU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSAiSJfv7sUU"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Подсказки</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>используйте numpy.dot для умножения матриц.</li>\n",
        "    <li>Убедитесь, что -1/m является вещественным значением (не целым), можно написать `float(1)` или `1.` </li>\n",
        "</ul>\n",
        "</p>\n",
        "\n"
      ],
      "id": "MSAiSJfv7sUU"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ydVtZiO67sUU"
      },
      "outputs": [],
      "source": [
        "# UNQ_C2 GRADED FUNCTION: gradientDescent\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # 'm' - количество строк в матрице x\n",
        "    m = len(x)\n",
        "  \n",
        "    for i in range(0, num_iters):\n",
        "        \n",
        "        # get z, the dot product of x and theta\n",
        "        z = np.dot(x,theta)\n",
        "        \n",
        "        # get the sigmoid of z\n",
        "        h = sigmoid(z)\n",
        "        \n",
        "        # calculate the cost function\n",
        "        J = (-1/m)*(np.dot(y.T,np.log(h)) + np.dot((1-y).T,np.log(1-h)))\n",
        "        \n",
        "        # update the weights theta\n",
        "        theta = theta - (alpha/m)*np.dot(x.T, h-y)\n",
        "        \n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "id": "ydVtZiO67sUU"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-rgunKJC7sUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bd9f10-ff4e-451d-b7ca-a8f41ae96333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.67094970.\n",
            "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
          ]
        }
      ],
      "source": [
        "# Проверка работоспособности функции\n",
        "np.random.seed(1)\n",
        "\n",
        "# создаем синтетический набор данных\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "\n",
        "# Градиентный спуск\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
      ],
      "id": "-rgunKJC7sUU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osa-AKd47sUU"
      },
      "source": [
        "\n",
        "#### Ожидаемый результат\n",
        "```\n",
        "The cost after training is 0.67094970.\n",
        "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
        "```"
      ],
      "id": "Osa-AKd47sUU"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OR9epnJx7sUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c24b998-b895-444c-aec9-e5d6d3c96f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Протестируйте функцию\n",
        "w1_unittest.test_gradientDescent(gradientDescent)"
      ],
      "id": "OR9epnJx7sUV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT0dgLCU7sUV"
      },
      "source": [
        "## Часть 2: Выделение признаков\n",
        "\n",
        "* Получив список твитов, извлеките признаки и сохраните их в матрице. \n",
        "\n",
        " * Первый признак - это количество положительных слов в твите.\n",
        " * Второй признак - это количество отрицательных слов в твите. \n",
        "* Затем обучите свой классификатор логистической регрессии по этим признаковым описаниям твитов.\n",
        "* Протестируйте классификатор на валидационном анаборе. \n",
        "\n",
        "### Задание: Реализуйте функцию extract_features. \n",
        "* Эта функция принимает один твит.\n",
        "* Обработайте твит с помощью импортированной функции process_tweet и сохраните список слов твита.\n",
        "* Повторите цикл по каждому слову в списке обработанных слов\n",
        " * Для каждого слова проверьте в частотном словаре 'freqs' количество случаев, когда это слово имеет положительную метку \"1\". (Проверьте наличие ключа (слово, 1.0)\n",
        " * Сделайте то же самое для подсчета связи слова с отрицательной меткой \"0\". (Проверьте наличие ключа (слово, 0.0))\n",
        "\n"
      ],
      "id": "uT0dgLCU7sUV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P36ray1y7sUV"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Подсказки</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Убедитесь, что вы правильно обрабатываете случаи, когда ключ (word, label) не найден в словаре. </li>\n",
        "</ul>\n",
        "</p>\n"
      ],
      "id": "P36ray1y7sUV"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pCbruw2k7sUV"
      },
      "outputs": [],
      "source": [
        "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
        "    '''\n",
        "    Input: \n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output: \n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "    # process_tweet - предобработка твитов\n",
        "    word_l = process_tweet(tweet)\n",
        "    \n",
        "    # 3 elements в форме вектора 1 x 3 \n",
        "    x = np.zeros((1, 3)) \n",
        "    \n",
        "    #bias - 1\n",
        "    x[0,0] = 1 \n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Проходим по всем словам в списке\n",
        "    for word in word_l:\n",
        "        \n",
        "        # увеличиваем счетчик при появлении метки 1\n",
        "        x[0,1] += freqs.get((word,1),0)\n",
        "        \n",
        "        # увеличиваем другой счетчик при появлении метки 0\n",
        "        x[0,2] += freqs.get((word,0),0)\n",
        "        \n",
        "    ### END CODE HERE ###\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ],
      "id": "pCbruw2k7sUV"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nSmHO9m07sUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747bc230-299c-4f9f-b43f-baf43e53303c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.000e+00 3.133e+03 6.100e+01]]\n"
          ]
        }
      ],
      "source": [
        "# Проверка функции\n",
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ],
      "id": "nSmHO9m07sUV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY0Iofeg7sUW"
      },
      "source": [
        "#### Ожидаемый вывод\n",
        "```\n",
        "[[1.000e+00 3.133e+03 6.100e+01]]\n",
        "```"
      ],
      "id": "vY0Iofeg7sUW"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RXYeH4eC7sUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaca2bef-d835-4c99-a049-47aebdae63b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Проверка функции\n",
        "# Если слова не было в словаре\n",
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
        "print(tmp2)"
      ],
      "id": "RXYeH4eC7sUW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEr9FKPv7sUW"
      },
      "source": [
        "#### Ожидаемый вывод\n",
        "```\n",
        "[[1. 0. 0.]]\n",
        "```"
      ],
      "id": "NEr9FKPv7sUW"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D_T8FPm7sUW",
        "outputId": "ac7010aa-cdfa-44e8-ec8c-6220f7b7e72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Тестирование функции\n",
        "w1_unittest.test_extract_features(extract_features, freqs)"
      ],
      "id": "5D_T8FPm7sUW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btLUB_9N7sUW"
      },
      "source": [
        "## Часть 3: Обучение модели\n",
        "\n",
        "Для обучения модели:\n",
        "* Соберите все признаки для обучающих примеров в матрицу X. \n",
        "* Вызовите функцию `gradientDescent`, которую вы реализовали выше.\n",
        "\n",
        "Эта часть реализована, прочитайет внимательно код и убедитесь, что вы все поняли."
      ],
      "id": "btLUB_9N7sUW"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "JDEVRVh47sUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbbf089-fa82-4a48-bc1c-8fdb26ca3eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after training is 0.22522315.\n",
            "The resulting vector of weights is [6e-08, 0.00053818, -0.0005583]\n"
          ]
        }
      ],
      "source": [
        "# собираем признаки в матрицу 'X'\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "# метки для обучающих примеров\n",
        "Y = train_y\n",
        "\n",
        "# Применяем градиентный спуск\n",
        "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "id": "JDEVRVh47sUW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm5FDfTB7sUW"
      },
      "source": [
        "**Ожидаемый результат**: \n",
        "\n",
        "```\n",
        "The cost after training is 0.22522315.\n",
        "The resulting vector of weights is [6e-08, 0.00053818, -0.0005583]\n",
        "```"
      ],
      "id": "Cm5FDfTB7sUW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks3sfmis7sUX"
      },
      "source": [
        "# Часть 4: Тестирование логистической регрессии\n",
        "\n",
        "#### Задание: реализуйте функцию `predict_tweet`\n",
        "предскажите, обладает ли твит положительной или отрицательной окраской.\n",
        "\n",
        "* Проиизведите предобработку новых твитов и извлеките для них признаки.\n",
        "* Примените обученную модель к признаковым описаниям новых твитов.\n",
        "* Примените сигмойду к логитам для предсказания класса (значение от 0 до 1).\n",
        "\n",
        "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
      ],
      "id": "ks3sfmis7sUX"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KvwbXfjC7sUX"
      },
      "outputs": [],
      "source": [
        "# UNQ_C4 GRADED FUNCTION: predict_tweet\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Input: \n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output: \n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # выделение признаков\n",
        "    x = extract_features(tweet, freqs)\n",
        "    \n",
        "    # предсказание\n",
        "    y_pred = sigmoid(np.dot(x, theta))\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return y_pred"
      ],
      "id": "KvwbXfjC7sUX"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "Jzg_akw07sUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5601c95c-2396-4cdd-d70e-2e0029916f80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 0.519275\n",
            "I am bad -> 0.494347\n",
            "this movie should have been great. -> 0.515979\n",
            "great -> 0.516065\n",
            "great great -> 0.532096\n",
            "great great great -> 0.548062\n",
            "great great great great -> 0.563929\n"
          ]
        }
      ],
      "source": [
        "# Тестирование функции\n",
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, theta)))    "
      ],
      "id": "Jzg_akw07sUX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svmslus57sUX"
      },
      "source": [
        "**Ожидаемый результат**: \n",
        "```\n",
        "I am happy -> 0.519275\n",
        "I am bad -> 0.494347\n",
        "this movie should have been great. -> 0.515979\n",
        "great -> 0.516065\n",
        "great great -> 0.532096\n",
        "great great great -> 0.548062\n",
        "great great great great -> 0.563929\n",
        "```"
      ],
      "id": "svmslus57sUX"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "X6zUX4vd7sUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6d62d0-71fa-4220-a8e8-45914fefcef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.83110307]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Проверьте на собственных твитах\n",
        "my_tweet = 'I am learning :)'\n",
        "predict_tweet(my_tweet, freqs, theta)"
      ],
      "id": "X6zUX4vd7sUX"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xC9ew5T17sUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339477e6-1637-4f9e-a4fd-197a1e6bc95c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Протестируйте функцию\n",
        "w1_unittest.test_predict_tweet(predict_tweet, freqs, theta)"
      ],
      "id": "xC9ew5T17sUX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh1k6tsI7sUY"
      },
      "source": [
        "## Оцените качество работы модели на тестовом наборе\n",
        "После обучения вашей модели с использованием приведенного выше обучающего набора проверьте, как ваша модель может работать с реальными, протестировав ее на тестовом наборе.\n",
        "\n",
        "#### Задание: Реализовать `test_logistic_regression` \n",
        "* Учитывая тестовые данные и веса вашей обученной модели, рассчитайте точность вашей модели логистической регрессии. \n",
        "* Используйте функцию \"predict_tweet\", чтобы делать прогнозы по каждому твиту в тестовом наборе.\n",
        "* Если прогноз > 0,5, установите классификацию модели 'y_hat' равной 1, в противном случае установите классификацию модели 'y_hat' равной 0.\n",
        "* Прогноз является точным, когда y_hat равно test_y. Суммируйте все случаи, когда они равны, и разделите на m."
      ],
      "id": "Bh1k6tsI7sUY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe6X8CbD7sUY"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Подсказки</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Используйте np.asarray() для перевода list в numpy массив</li>\n",
        "    <li>Используйте numpy.squeeze() для того чтобы убрать ненужную размерность ((m,1) -> (m,)) [[]] -> [] </li>\n",
        "</ul>\n",
        "</p>"
      ],
      "id": "fe6X8CbD7sUY"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bIf2sOtp7sUY"
      },
      "outputs": [],
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output: \n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Список предсказаний\n",
        "    y_hat = []\n",
        "    \n",
        "    for tweet in test_x:\n",
        "        # метка для предсказанного твита\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        \n",
        "        if y_pred > 0.5:\n",
        "            # добавляем 1.0 к списку\n",
        "            y_hat.append(1.0)\n",
        "        else:\n",
        "            # добавляем 0 к списку\n",
        "            y_hat.append(0.0)\n",
        "\n",
        "    # Сейчас y_hat - это list, f test_y - массив (m,1) (array)\n",
        "    # переведите обе переменные к типу one-dimensional arrays, чтобы использовать оператор сравнения '=='\n",
        "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return accuracy"
      ],
      "id": "bIf2sOtp7sUY"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BslZcmeY7sUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90b599f5-0892-444b-da21-998f54a22a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.9950\n"
          ]
        }
      ],
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "id": "BslZcmeY7sUY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28JG0FC97sUY"
      },
      "source": [
        "#### Ожидаемый результат: \n",
        "```0.9950```  \n",
        "Pretty good!"
      ],
      "id": "28JG0FC97sUY"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CpdeDOs87sUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4295359-ac1e-402a-a590-098b77f37559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m All tests passed\n"
          ]
        }
      ],
      "source": [
        "# Протестируйте функцию\n",
        "w1_unittest.unittest_test_logistic_regression(test_logistic_regression, freqs, theta)"
      ],
      "id": "CpdeDOs87sUY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYWkPcK_7sUY"
      },
      "source": [
        "# Part 5: Анализ ошибок\n",
        "\n",
        "В этой части вы увидите несколько твитов, которые ваша модель неправильно классифицировала. Как вы думаете, почему произошла неправильная классификация? В частности, какие твиты неправильно классифицирует ваша модель?"
      ],
      "id": "mYWkPcK_7sUY"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aCi4R9n37sUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a4ceac-7204-4160-892f-4fd136b448cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Predicted Tweet\n",
            "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
            "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
            "1\t0.48901497\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
            "http://t.co/UGQzOx0huu\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48418949\tb\"i'm play brain dot braindot\"\n",
            "THE TWEET IS: off to the park to get some sunlight : )\n",
            "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
            "1\t0.49636374\tb'park get sunlight'\n",
            "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
            "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
            "1\t0.48237069\tb'uff itna miss karhi thi ap :p'\n",
            "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
            "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
            "0\t0.50988239\tb'u prob fun david'\n",
            "THE TWEET IS: pats jay : (\n",
            "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
            "0\t0.50040365\tb'pat jay'\n",
            "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
            "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
            "0\t0.50000002\tb'belov grandmoth'\n",
            "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
            "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
            "0\t0.50648681\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n"
          ]
        }
      ],
      "source": [
        "# Анализ ошибок\n",
        "print('Label Predicted Tweet')\n",
        "for x,y in zip(test_x,test_y):\n",
        "    y_hat = predict_tweet(x, freqs, theta)\n",
        "\n",
        "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
        "        print('THE TWEET IS:', x)\n",
        "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
        "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
      ],
      "id": "aCi4R9n37sUZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "208vDbb27sUZ"
      },
      "source": [
        "# Part 6: Предсказание для собственных твитов"
      ],
      "id": "208vDbb27sUZ"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dWblpEcq7sUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678cd932-59d9-49b2-cd4d-e6bddaedf900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.48125423]]\n",
            "Negative sentiment\n"
          ]
        }
      ],
      "source": [
        "# Придумайте и предскажите тональность собственных, интересных твитов\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')"
      ],
      "id": "dWblpEcq7sUZ"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-6DvWRU_KhSH"
      },
      "id": "-6DvWRU_KhSH",
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LR_tweets(Nastasyuk).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Th9hhPrF7sUQ",
        "eyPDkAvU7sUR",
        "Uenru1Ch7sUT"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}